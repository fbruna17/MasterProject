Attention And Bigru
Training loss: 1.1853, validation loss: 0.4216, best val loss: 0.4216
Training loss: 0.2105, validation loss: 0.1904, best val loss: 0.1904
Training loss: 0.1856, validation loss: 0.1791, best val loss: 0.1791
Training loss: 0.1756, validation loss: 0.1654, best val loss: 0.1654
Training loss: 0.1677, validation loss: 0.1588, best val loss: 0.1588
Training loss: 0.1525, validation loss: 0.1364, best val loss: 0.1364
Training loss: 0.1305, validation loss: 0.1215, best val loss: 0.1215
Training loss: 0.1206, validation loss: 0.1047, best val loss: 0.1047
Training loss: 0.1140, validation loss: 0.1009, best val loss: 0.1009
Training loss: 0.1088, validation loss: 0.0959, best val loss: 0.0959
Training loss: 0.1043, validation loss: 0.0922, best val loss: 0.0922
Training loss: 0.0980, validation loss: 0.0827, best val loss: 0.0827
Training loss: 0.0930, validation loss: 0.0822, best val loss: 0.0822
Training loss: 0.0897, validation loss: 0.0768, best val loss: 0.0768
Training loss: 0.0872, validation loss: 0.0754, best val loss: 0.0754
Training loss: 0.0853, validation loss: 0.0747, best val loss: 0.0747
Training loss: 0.0834, validation loss: 0.0727, best val loss: 0.0727
Training loss: 0.0819, validation loss: 0.0707, best val loss: 0.0707
Training loss: 0.0804, validation loss: 0.0703, best val loss: 0.0703
Training loss: 0.0792, validation loss: 0.0698, best val loss: 0.0698
Training loss: 0.0782, validation loss: 0.0692, best val loss: 0.0692
Training loss: 0.0772, validation loss: 0.0682, best val loss: 0.0682
Training loss: 0.0762, validation loss: 0.0683, best val loss: 0.0682
Training loss: 0.0755, validation loss: 0.0666, best val loss: 0.0666
Training loss: 0.0747, validation loss: 0.0657, best val loss: 0.0657
Training loss: 0.0741, validation loss: 0.0655, best val loss: 0.0655
Training loss: 0.0735, validation loss: 0.0644, best val loss: 0.0644
Training loss: 0.0730, validation loss: 0.0638, best val loss: 0.0638
Training loss: 0.0726, validation loss: 0.0640, best val loss: 0.0638
Training loss: 0.0723, validation loss: 0.0635, best val loss: 0.0635
Training loss: 0.0720, validation loss: 0.0634, best val loss: 0.0634
Training loss: 0.0718, validation loss: 0.0629, best val loss: 0.0629
Training loss: 0.0717, validation loss: 0.0628, best val loss: 0.0628
Training loss: 0.0715, validation loss: 0.0626, best val loss: 0.0626
Training loss: 0.0715, validation loss: 0.0626, best val loss: 0.0626
Training loss: 0.0797, validation loss: 0.0621, best val loss: 0.0621
Training loss: 0.0734, validation loss: 0.0611, best val loss: 0.0611
Training loss: 0.0714, validation loss: 0.0587, best val loss: 0.0587
Training loss: 0.0696, validation loss: 0.0572, best val loss: 0.0572
Training loss: 0.0696, validation loss: 0.0572, best val loss: 0.0572
Training loss: 0.0679, validation loss: 0.0578, best val loss: 0.0572
Training loss: 0.0665, validation loss: 0.0604, best val loss: 0.0572
Training loss: 0.0650, validation loss: 0.0565, best val loss: 0.0565
Training loss: 0.0637, validation loss: 0.0556, best val loss: 0.0556
Training loss: 0.0627, validation loss: 0.0530, best val loss: 0.0530
Training loss: 0.0615, validation loss: 0.0532, best val loss: 0.0530
Training loss: 0.0604, validation loss: 0.0548, best val loss: 0.0530
Training loss: 0.0595, validation loss: 0.0534, best val loss: 0.0530
Training loss: 0.0587, validation loss: 0.0539, best val loss: 0.0530
Training loss: 0.0578, validation loss: 0.0518, best val loss: 0.0518
Training loss: 0.0569, validation loss: 0.0515, best val loss: 0.0515
Training loss: 0.0563, validation loss: 0.0527, best val loss: 0.0515
Training loss: 0.0555, validation loss: 0.0504, best val loss: 0.0504
Training loss: 0.0550, validation loss: 0.0500, best val loss: 0.0500
Training loss: 0.0543, validation loss: 0.0502, best val loss: 0.0500
Training loss: 0.0538, validation loss: 0.0499, best val loss: 0.0499
Training loss: 0.0533, validation loss: 0.0504, best val loss: 0.0499
Training loss: 0.0528, validation loss: 0.0505, best val loss: 0.0499
Training loss: 0.0523, validation loss: 0.0496, best val loss: 0.0496
Training loss: 0.0519, validation loss: 0.0497, best val loss: 0.0496
Training loss: 0.0516, validation loss: 0.0490, best val loss: 0.0490
Training loss: 0.0513, validation loss: 0.0493, best val loss: 0.0490
Training loss: 0.0510, validation loss: 0.0492, best val loss: 0.0490
Training loss: 0.0508, validation loss: 0.0495, best val loss: 0.0490
Training loss: 0.0504, validation loss: 0.0488, best val loss: 0.0488
Training loss: 0.0503, validation loss: 0.0489, best val loss: 0.0488
Training loss: 0.0502, validation loss: 0.0490, best val loss: 0.0488
Training loss: 0.0502, validation loss: 0.0490, best val loss: 0.0488
Training loss: 0.0501, validation loss: 0.0491, best val loss: 0.0488
Training loss: 0.0500, validation loss: 0.0489, best val loss: 0.0488
Training loss: 0.0573, validation loss: 0.0508, best val loss: 0.0488
Training loss: 0.0536, validation loss: 0.0529, best val loss: 0.0488
Training loss: 0.0527, validation loss: 0.0523, best val loss: 0.0488
Training loss: 0.0519, validation loss: 0.0507, best val loss: 0.0488
Training loss: 0.0516, validation loss: 0.0500, best val loss: 0.0488
Training loss: 0.0508, validation loss: 0.0501, best val loss: 0.0488
Training loss: 0.0503, validation loss: 0.0503, best val loss: 0.0488
Training loss: 0.0497, validation loss: 0.0482, best val loss: 0.0482
Training loss: 0.0491, validation loss: 0.0481, best val loss: 0.0481
Training loss: 0.0485, validation loss: 0.0504, best val loss: 0.0481
Training loss: 0.0481, validation loss: 0.0513, best val loss: 0.0481
Training loss: 0.0476, validation loss: 0.0487, best val loss: 0.0481
Training loss: 0.0470, validation loss: 0.0508, best val loss: 0.0481
Training loss: 0.0467, validation loss: 0.0465, best val loss: 0.0465
Training loss: 0.0461, validation loss: 0.0490, best val loss: 0.0465
Training loss: 0.0456, validation loss: 0.0471, best val loss: 0.0465
Training loss: 0.0452, validation loss: 0.0469, best val loss: 0.0465
Training loss: 0.0448, validation loss: 0.0472, best val loss: 0.0465
Training loss: 0.0444, validation loss: 0.0471, best val loss: 0.0465
Training loss: 0.0441, validation loss: 0.0465, best val loss: 0.0465
Training loss: 0.0437, validation loss: 0.0480, best val loss: 0.0465
Training loss: 0.0433, validation loss: 0.0480, best val loss: 0.0465
Training loss: 0.0430, validation loss: 0.0477, best val loss: 0.0465
Training loss: 0.0427, validation loss: 0.0479, best val loss: 0.0465
Training loss: 0.0425, validation loss: 0.0471, best val loss: 0.0465
Training loss: 0.0423, validation loss: 0.0475, best val loss: 0.0465
Training loss: 0.0421, validation loss: 0.0468, best val loss: 0.0465
Training loss: 0.0420, validation loss: 0.0472, best val loss: 0.0465
Training loss: 0.0418, validation loss: 0.0469, best val loss: 0.0465
Training loss: 0.0417, validation loss: 0.0469, best val loss: 0.0465
